# -*- coding: utf-8 -*-
# =============================================================================
# --- å¯¼å…¥æ ¸å¿ƒåº“ ---
# =============================================================================
import os
import sys
import subprocess
import importlib.util
import re
import configparser
import tempfile
from pathlib import Path

# --- Flask Web æ¡†æ¶åº“ ---
from flask import Flask, render_template, request, send_file, jsonify

# --- APIåº“ï¼ˆFlaskè¾“å…¥éœ€è¦ï¼Œä¼˜å…ˆå¯¼å…¥ï¼‰
import tkinter as tk
from tkinter import simpledialog, messagebox

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
# å»¶è¿Ÿå¯¼å…¥é‡é‡çº§åº“ï¼ˆåŠ å¿«å¯åŠ¨é€Ÿåº¦ï¼‰
def import_heavy_libraries():
    """å»¶è¿Ÿå¯¼å…¥é‡é‡çº§åº“ï¼Œåªåœ¨éœ€è¦æ—¶æ‰å¯¼å…¥"""
    global fitz, convert_from_path, pytesseract, Image, requests
    global pd, load_workbook, Font, Alignment, PatternFill, Border, Side
    
    # æ‰“å°åŠ è½½ä¿¡æ¯
    print("æ­£åœ¨åŠ è½½åˆ†æåº“...")
    
    # è¿™é‡Œæˆ‘ä»¬åªå¯¼å…¥ Python åº“ï¼Œä¸ä¾èµ–æœ¬åœ°å¯æ‰§è¡Œæ–‡ä»¶
    import fitz
    from pdf2image import convert_from_path
    import pytesseract
    from PIL import Image
    import requests
    import pandas as pd
    from openpyxl import load_workbook
    from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
    
    print("âœ“ åˆ†æåº“åŠ è½½å®Œæˆ")

# LLMç›¸å…³å¸¸é‡
LLM_URL = "https://api.deepseek.com/v1/chat/completions"
FIELDS = ["ç ”ç©¶èƒŒæ™¯", "ç ”ç©¶æ–¹æ³•", "å®éªŒè®¾è®¡", "ç»“æœåˆ†æ", "è®¨è®º"]

# æ ¸å¿ƒé€»è¾‘å‡½æ•°
def clean_bullet(text):
    """æ¸…ç†æ–‡æœ¬ä¸­çš„å¤šä½™ç¬¦å·"""
    text = re.sub(r'^[\s*\-*â€¢Â·#]+', '', text, flags=re.MULTILINE)
    text = text.replace('**', '').replace('*', '').replace('###', '').replace('##', '').replace('#', '')
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()

def smart_extract_text(pdf_path, min_chars=1000):
    """æ™ºèƒ½æå–PDFæ–‡æœ¬ï¼Œä¸è¶³æ—¶å°è¯•OCR"""
    print(f"    å°è¯•ç›´æ¥æå–æ–‡æœ¬...")
    try:
        doc = fitz.open(pdf_path)
        text = "\n".join([page.get_text() for page in doc])
        effective_chars = len(''.join(text.split()))
        zh_count = sum('\u4e00' <= c <= '\u9fff' for c in text)
        en_count = sum(c.isalpha() for c in text)
        print(f"    æå–åˆ° {len(text)} ä¸ªå­—ç¬¦ï¼ˆæœ‰æ•ˆå­—ç¬¦: {effective_chars}ï¼Œä¸­æ–‡: {zh_count}ï¼Œè‹±æ–‡: {en_count}ï¼‰")
        
        if effective_chars >= min_chars or (effective_chars > 500 and (zh_count > 100 or en_count > 300)):
            print(f"    âœ… æ–‡æœ¬æå–æˆåŠŸ")
            return text
            
        pages = len(doc)
        avg_chars_per_page = effective_chars / pages if pages > 0 else 0
        if avg_chars_per_page > 200:
            print(f"    âœ… æ–‡æœ¬æå–æˆåŠŸï¼ˆæ¯é¡µå¹³å‡ {avg_chars_per_page:.0f} ä¸ªå­—ç¬¦ï¼‰")
            return text
            
        print(f"    âš ï¸ æ–‡æœ¬è¿‡å°‘ï¼Œåˆ‡æ¢åˆ°OCRæ¨¡å¼...")
        print(f"    å¼€å§‹OCRè¯†åˆ«ï¼ˆè¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰...")
        return ocr_from_pdf(pdf_path)
    except Exception as e:
        print(f"    âŒ æ–‡æœ¬æå–å¤±è´¥: {e}")
        return ""

def ocr_from_pdf(pdf_path):
    """ä½¿ç”¨OCRè¯†åˆ«PDFä¸­çš„æ–‡æœ¬"""
    try:
        # åœ¨Webåº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ä¸ä¾èµ–æœ¬åœ°å¯æ‰§è¡Œæ–‡ä»¶ï¼Œ
        # è€Œæ˜¯å‡è®¾æœåŠ¡å™¨ç¯å¢ƒå·²ç»å®‰è£…äº†tesseractå’Œpoppler
        images = convert_from_path(pdf_path, dpi=200)
        text_all = ""
        total_pages = len(images)
        for idx, img in enumerate(images, 1):
            print(f"    æ­£åœ¨è¯†åˆ«ç¬¬ {idx}/{total_pages} é¡µ...")
            t = pytesseract.image_to_string(img, lang='chi_sim+eng')
            text_all += f"\n---- ç¬¬{idx}é¡µ ----\n{t}\n"
        print(f"    âœ… OCRè¯†åˆ«å®Œæˆ")
        return text_all
    except Exception as e:
        print(f"    âŒ OCRé”™è¯¯: {e}")
        # è¿™é‡Œä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œç¡®ä¿ç¨‹åºç»§ç»­è¿è¡Œ
        return ""

def extract_key_sections(pdf_text, max_length=30000):
    """æ™ºèƒ½æå–æ–‡æœ¬å…³é”®éƒ¨åˆ†ä»¥èŠ‚çœLLM token"""
    if len(pdf_text) <= max_length:
        return pdf_text
    print(f"    æ–‡æœ¬è¿‡é•¿ï¼ˆ{len(pdf_text)}å­—ç¬¦ï¼‰ï¼Œæ™ºèƒ½æå–å…³é”®å†…å®¹...")
    
    key_sections = {
        'æ‘˜è¦': ['æ‘˜è¦', 'abstract', 'summary', 'æ¦‚è¦'],
        'å¼•è¨€': ['å¼•è¨€', 'introduction', 'å‰è¨€', 'èƒŒæ™¯', 'background'],
        'æ–¹æ³•': ['æ–¹æ³•', 'method', 'methodology', 'ææ–™ä¸æ–¹æ³•', 'materials and methods', 'å®éªŒæ–¹æ³•'],
        'ç»“æœ': ['ç»“æœ', 'result', 'findings', 'å®éªŒç»“æœ', 'ç ”ç©¶ç»“æœ'],
        'è®¨è®º': ['è®¨è®º', 'discussion', 'åˆ†æ', 'analysis'],
        'ç»“è®º': ['ç»“è®º', 'conclusion', 'æ€»ç»“', 'summary and conclusion']
    }
    
    extracted_parts = []
    used_length = 0
    header_length = min(5000, len(pdf_text))
    extracted_parts.append(("å¼€å¤´éƒ¨åˆ†", pdf_text[:header_length]))
    used_length += header_length
    
    text_lower = pdf_text.lower()
    found_sections = []
    
    for section_name, keywords in key_sections.items():
        for keyword in keywords:
            positions = []
            start = 0
            while True:
                pos = text_lower.find(keyword.lower(), start)
                if pos == -1:  
                    break
                if pos == 0 or pdf_text[pos-1] in '\n\r':
                    positions.append(pos)
                start = pos + 1
            
            if positions:
                section_start = positions[0]
                section_end = min(section_start + 5000, len(pdf_text))
                section_content = pdf_text[section_start:section_end]
                found_sections.append((section_name, section_start, section_content))
                break
    
    found_sections.sort(key=lambda x: x[1])
    
    for section_name, _, content in found_sections:
        if used_length + len(content) <= max_length:
            extracted_parts.append((section_name, content))
            used_length += len(content)
            print(f"    âœ“ æå–äº† {section_name} éƒ¨åˆ†")
    
    if used_length < max_length - 3000:
        tail_length = min(3000, max_length - used_length)
        extracted_parts.append(("ç»“å°¾éƒ¨åˆ†", pdf_text[-tail_length:]))
        print(f"    âœ“ æå–äº†ç»“å°¾éƒ¨åˆ†")
    
    result = []
    for name, content in extracted_parts:
        result.append(f"\n\n===== {name} =====\n")
        result.append(content)
    
    final_text = "".join(result)
    print(f"    æ™ºèƒ½æå–å®Œæˆï¼Œä¿ç•™äº† {len(final_text)} å­—ç¬¦")
    return final_text

def build_prompt(pdf_text):
    """æ„å»ºå‘é€ç»™LLMçš„Prompt"""
    max_length = 30000
    pdf_text = extract_key_sections(pdf_text, max_length)
    instruction = "è¯·ä»ä»¥ä¸‹è®ºæ–‡å†…å®¹ä¸­åˆ†åˆ«æå–å¦‚ä¸‹ç»“æ„åŒ–ä¿¡æ¯ï¼š\n"
    instruction += "".join([f"- {field}\n" for field in FIELDS])
    instruction += "\næ¯ä¸ªè¦ç‚¹è¯·åˆ†è¡Œï¼Œæ­£æ–‡å¦‚ä¸‹ï¼š\n\n"
    return instruction + pdf_text

def extract_fields_with_llm(pdf_text, api_key):
    """è°ƒç”¨LLM APIè¿›è¡Œåˆ†æ"""
    prompt = build_prompt(pdf_text)
    HEADERS = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿è®ºæ–‡åˆ†æçš„å­¦æœ¯åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®æå–è®ºæ–‡ä¸­çš„å…³é”®ä¿¡æ¯"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 4000
    }
    try:
        response = requests.post(LLM_URL, headers=HEADERS, json=payload, timeout=60)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.Timeout:
        print("    âš ï¸ APIè¯·æ±‚è¶…æ—¶ï¼Œå°è¯•ä½¿ç”¨æ›´çŸ­çš„æ–‡æœ¬...")
        shorter_text = extract_key_sections(pdf_text, 15000)
        prompt = build_prompt(shorter_text)
        payload["messages"][1]["content"] = prompt
        response = requests.post(LLM_URL, headers=HEADERS, json=payload, timeout=60)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        print(f"    âš ï¸ APIè¯·æ±‚é”™è¯¯: {e}")
        raise

def parse_llm_output(text):
    """è§£æLLMè¿”å›çš„æ–‡æœ¬"""
    # ä¿®å¤ï¼šç§»é™¤LLMè¾“å‡ºä¸­å¯èƒ½å‡ºç°çš„å¼€å¤´å’Œç»“å°¾çš„é¢å¤–æ–¹æ‹¬å·
    text = text.strip()
    if text.startswith('ã€') and text.endswith('ã€‘'):
        text = text[1:-1]
    
    result = {field: "" for field in FIELDS}
    text = text.replace('###', '').replace('##', '')
    for field in FIELDS:
        if field in text:
            start = text.find(field)
            next_field_pos = [text.find(f) for f in FIELDS if f != field and text.find(f) > start]
            end = min(next_field_pos) if next_field_pos else len(text)
            content = text[start + len(field):end].strip()
            if content.startswith(':') or content.startswith('ï¼š'):
                content = content[1:].strip()
            result[field] = clean_bullet(content)
    return result

def beautify_excel(filepath):
    """ç¾åŒ–Excelæ–‡ä»¶æ ¼å¼"""
    wb = load_workbook(filepath)
    ws = wb.active
    
    header_fill = PatternFill(fill_type="solid", fgColor="BDD7EE")
    header_font = Font(bold=True, color="000000")
    header_alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
    thin_border = Border(
        left=Side(style='thin', color='808080'),
        right=Side(style='thin', color='808080'),
        top=Side(style='thin', color='808080'),
        bottom=Side(style='thin', color='808080')
    )
    medium_border = Border(
        left=Side(style='medium', color='000000'),
        right=Side(style='medium', color='000000'),
        top=Side(style='medium', color='000000'),
        bottom=Side(style='medium', color='000000')
    )
    
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = header_alignment
        cell.border = medium_border
    
    for row in ws.iter_rows(min_row=2):
        for cell in row:
            cell.alignment = Alignment(wrap_text=True, vertical="top", horizontal="left")
            cell.border = thin_border
    
    for column_cells in ws.columns:
        max_length = max(len(str(cell.value)) if cell.value else 0 for cell in column_cells)
        col_letter = column_cells[0].column_letter
        ws.column_dimensions[col_letter].width = min(max_length + 6, 55)
    
    ws.row_dimensions[1].height = 30
    for row_num in range(2, ws.max_row + 1):
        ws.row_dimensions[row_num].height = 100
    
    wb.save(filepath)
    print("    âœ… Excelæ ¼å¼ç¾åŒ–å®Œæˆ")

def process_pdfs(pdf_files, api_key):
    """å¤„ç†ä¸Šä¼ çš„PDFæ–‡ä»¶åˆ—è¡¨"""
    import_heavy_libraries() # ç¡®ä¿åº“å·²åŠ è½½
    
    if not api_key.strip().startswith("sk-"):
        print("âŒ APIå¯†é’¥æ ¼å¼ä¸æ­£ç¡®")
        return [{"æ–‡ä»¶å": "APIå¯†é’¥æ ¼å¼ä¸æ­£ç¡®"}]
        
    HEADERS = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    RESULTS = []
    
    for idx, pdf_file in enumerate(pdf_files, 1):
        filename = pdf_file.filename
        print(f"ğŸ“„ [{idx}/{len(pdf_files)}] æ­£åœ¨å¤„ç†: {filename}")
        
        # å°†æ–‡ä»¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            pdf_file.save(tmp.name)
            pdf_path = tmp.name
            
        try:
            text = smart_extract_text(pdf_path)
            if len(text.strip()) < 100:
                print("    âš ï¸ æå–çš„æ–‡æœ¬å¤ªå°‘ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                continue
            
            print("    æ­£åœ¨è°ƒç”¨LLMåˆ†æ...")
            llm_output = extract_fields_with_llm(text, api_key)
            structured_data = parse_llm_output(llm_output)
            structured_data["æ–‡ä»¶å"] = filename
            RESULTS.append(structured_data)
            print("    âœ… å¤„ç†æˆåŠŸ\n")
            
        except Exception as e:
            print(f"    âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}\n")
            error_data = {field: "å¤„ç†å¤±è´¥" for field in FIELDS}
            error_data["æ–‡ä»¶å"] = filename
            error_data["é”™è¯¯ä¿¡æ¯"] = str(e)
            RESULTS.append(error_data)
            
        finally:
            os.unlink(pdf_path) # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            
    return RESULTS

def generate_excel(results):
    """å°†ç»“æœç”ŸæˆExcelæ–‡ä»¶"""
    if not results:
        return None
    
    # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä¿å­˜Excelï¼Œç„¶åè¿”å›
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
        df = pd.DataFrame(results)
        df.to_excel(tmp.name, index=False)
        tmp.close()
        beautify_excel(tmp.name)
        return tmp.name
        
# =============================================================================
# --- Flask åº”ç”¨åˆå§‹åŒ– ---
# =============================================================================
app = Flask(__name__)

# --- è·¯ç”±å®šä¹‰ ---
@app.route('/')
def index():
    """ä¸»é¡µï¼Œè¿”å›ä¸Šä¼ æ–‡ä»¶ç•Œé¢"""
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_pdfs():
    """å¤„ç†PDFåˆ†æè¯·æ±‚"""
    pdf_files = request.files.getlist('pdfs')
    api_key = request.form.get('api_key')
    
    if not pdf_files:
        return jsonify({"error": "è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªPDFæ–‡ä»¶"}), 400
        
    print(f"æ”¶åˆ°è¯·æ±‚ï¼šå¤„ç† {len(pdf_files)} ä¸ªæ–‡ä»¶")
    results = process_pdfs(pdf_files, api_key)
    
    if not results:
        return jsonify({"error": "å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æˆ–æ–‡ä»¶å†…å®¹"}), 500

    output_file_path = generate_excel(results)
    if not output_file_path:
        return jsonify({"error": "ç”ŸæˆExcelæ–‡ä»¶å¤±è´¥"}), 500
        
    response = send_file(output_file_path, as_attachment=True, download_name='EggScan_Result.xlsx')
    
    # åˆ é™¤Excelä¸´æ—¶æ–‡ä»¶
    @response.call_on_close
    def remove_file():
        os.unlink(output_file_path)
    
    print("âœ… Excelæ–‡ä»¶å·²å‘é€ï¼Œä»»åŠ¡å®Œæˆã€‚")
    return response

# --- ç¨‹åºä¸»å…¥å£ ---
if __name__ == '__main__':
    # å»¶è¿Ÿå¯¼å…¥é‡é‡çº§åº“
    import_heavy_libraries()
    
    # è¿è¡ŒFlaskåº”ç”¨ï¼Œhost='0.0.0.0'è®©å±€åŸŸç½‘å†…å…¶ä»–è®¾å¤‡å¯è®¿é—®
    app.run(host='0.0.0.0', port=5000)
