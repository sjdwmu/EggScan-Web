# -*- coding: utf-8 -*-
# =============================================================================
# --- å¯¼å…¥æ ¸å¿ƒåº“ ---
# =============================================================================
import os
import re
import tempfile

# --- Flask Web æ¡†æ¶åº“ ---
from flask import Flask, render_template, request, send_file, jsonify

# (æ³¨é‡Š) ç§»é™¤äº† tkinterï¼Œå› ä¸ºå®ƒç”¨äºæ¡Œé¢GUIï¼Œåœ¨WebæœåŠ¡å™¨ä¸Šä¸é€‚ç”¨ä¸”ä¼šå¼•å‘é”™è¯¯ã€‚

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
# (æ³¨é‡Š) å°†æ‰€æœ‰é‡é‡çº§åº“çš„å¯¼å…¥éƒ½æ”¾åœ¨è¿™ä¸ªå‡½æ•°é‡Œï¼Œåœ¨ç¨‹åºå¯åŠ¨æ—¶ä¸åŠ è½½ï¼Œåœ¨ç”¨æˆ·è¯·æ±‚æ—¶æ‰åŠ è½½ã€‚
def import_heavy_libraries():
    """å»¶è¿Ÿå¯¼å…¥é‡é‡çº§åº“ï¼Œåªåœ¨éœ€è¦æ—¶æ‰å¯¼å…¥"""
    global fitz, convert_from_path, pytesseract, Image, requests
    global pd, load_workbook, Font, Alignment, PatternFill, Border, Side
    
    print("æ­£åœ¨åŠ è½½åˆ†æåº“...")
    
    import fitz
    # (æ³¨é‡Š) pdf2image åœ¨éWindowsæœåŠ¡å™¨ä¸Šéƒ¨ç½²å¯èƒ½éœ€è¦é¢å¤–é…ç½®popplerè·¯å¾„ï¼Œè¿™é‡Œå‡è®¾ç¯å¢ƒå·²é…ç½®å¥½
    from pdf2image import convert_from_path
    import pytesseract
    from PIL import Image
    import requests
    import pandas as pd
    from openpyxl import load_workbook
    from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
    
    print("âœ“ åˆ†æåº“åŠ è½½å®Œæˆ")

# (æ³¨é‡Š) LLMç›¸å…³å¸¸é‡ä¿æŒä¸å˜
LLM_URL = "https://api.deepseek.com/v1/chat/completions"

# =============================================================================
# --- (æ”¹åŠ¨éƒ¨åˆ† 1): æ›´æ–°æ ¸å¿ƒåˆ†æå‡½æ•° ---
# =============================================================================

def call_llm_for_analysis(pdf_text, api_key):
    """
    (æ³¨é‡Š)
    è¿™æ˜¯æœ¬æ¬¡å‡çº§çš„æ ¸å¿ƒå‡½æ•°ã€‚
    å®ƒå–ä»£äº†æ—§çš„ build_prompt å’Œ extract_fields_with_llm å‡½æ•°ã€‚
    åŠŸèƒ½ï¼šæ„å»ºæ–°çš„Promptï¼Œè°ƒç”¨LLM APIï¼Œå¹¶è¿”å›åŸå§‹çš„ã€æœªç»è§£æçš„åˆ†æç»“æœã€‚
    """
    # (æ³¨é‡Š) é¦–å…ˆï¼Œå¯¹è¿‡é•¿çš„æ–‡æœ¬è¿›è¡Œæ™ºèƒ½æˆªå–ï¼Œè¿™éƒ¨åˆ†é€»è¾‘ä¿ç•™
    max_length = 30000
    truncated_text = extract_key_sections(pdf_text, max_length)

    # (æ³¨é‡Š) è¿™æ˜¯å…¨æ–°çš„Promptï¼ŒæŒ‡å¯¼LLMæŒ‰â€œä¸­æ–‡æç‚¼-æ ¸å¿ƒåŸæ–‡-åŸæ–‡ç¿»è¯‘â€çš„æ ¼å¼è¾“å‡º
    prompt = f"""
    è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„ç”Ÿç‰©åŒ»å­¦ç ”ç©¶å‘˜ï¼Œä»”ç»†é˜…è¯»ä»¥ä¸‹è‹±æ–‡æ–‡çŒ®å†…å®¹ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯ï¼š
    1. ç”¨ä¸­æ–‡ç²¾ç‚¼åœ°æ€»ç»“å‡ºæœ€é‡è¦çš„æ ¸å¿ƒè§‚ç‚¹å’Œå‘ç°ï¼Œæ¯ä¸€ç‚¹ä½œä¸ºä¸€æ®µã€‚
    2. åœ¨æ¯ä¸€æ®µä¸­æ–‡æ€»ç»“ä¸‹æ–¹ï¼Œé™„ä¸Šè¯¥æ€»ç»“æ‰€ä¾æ®çš„æœ€æ ¸å¿ƒçš„1-2å¥è‹±æ–‡åŸæ–‡ã€‚
    3. æœ€åï¼Œå°†ä½ é™„ä¸Šçš„é‚£å¥â€œè‹±æ–‡åŸæ–‡â€ç¿»è¯‘æˆä¸­æ–‡ã€‚

    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼Œæ¯ä¸ªè§‚ç‚¹ä¹‹é—´ç”¨ '---' åˆ†éš”ï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„è§£é‡Šï¼š
    [ä¸­æ–‡æç‚¼]: è¿™é‡Œæ˜¯ä½ çš„ä¸­æ–‡æ€»ç»“å†…å®¹ã€‚
    [æ ¸å¿ƒåŸæ–‡]: Here is the original English quote.
    [åŸæ–‡ç¿»è¯‘]: è¿™é‡Œæ˜¯å¯¹ä¸Šé¢é‚£å¥æ ¸å¿ƒåŸæ–‡çš„ä¸­æ–‡ç¿»è¯‘ã€‚
    ---
    [ä¸­æ–‡æç‚¼]: è¿™é‡Œæ˜¯ç¬¬äºŒæ®µä¸­æ–‡æ€»ç»“ã€‚
    [æ ¸å¿ƒåŸæ–‡]: Here is another key English sentence.
    [åŸæ–‡ç¿»è¯‘]: è¿™æ˜¯å¯¹ç¬¬äºŒå¥åŸæ–‡çš„ç¿»è¯‘ã€‚
    """

    # (æ³¨é‡Š) System arole ä¿æŒä¸å˜ï¼ŒæŒ‡å¯¼AIçš„è§’è‰²
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿è®ºæ–‡åˆ†æçš„å­¦æœ¯åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®ã€ç²¾ç‚¼åœ°æå–è®ºæ–‡ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„æ ¼å¼è¾“å‡ºã€‚"
    
    # (æ³¨é‡Š) æ„é€ å®Œæ•´çš„è¯·æ±‚å†…å®¹
    user_content = f"è¯·åˆ†æä»¥ä¸‹è®ºæ–‡å†…å®¹ï¼š\n\n{truncated_text}\n\n{prompt}"
    
    HEADERS = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content}
        ],
        "temperature": 0.5, # (æ³¨é‡Š) ç¨å¾®é™ä½æ¸©åº¦ï¼Œè®©è¾“å‡ºæ›´ç¨³å®šã€èšç„¦
        "max_tokens": 4096  # (æ³¨é‡Š) ä¿æŒè¶³å¤Ÿçš„è¾“å‡ºç©ºé—´
    }
    
    try:
        # (æ³¨é‡Š) APIè¯·æ±‚é€»è¾‘åŸºæœ¬ä¸å˜ï¼Œä½†å¢åŠ äº†å¯¹é‡è¯•é€»è¾‘çš„ç®€åŒ–
        print("    æ­£åœ¨è°ƒç”¨LLM API...")
        response = requests.post(LLM_URL, headers=HEADERS, json=payload, timeout=120) # (æ³¨é‡Š) å»¶é•¿è¶…æ—¶æ—¶é—´
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        print(f"    âš ï¸ APIè¯·æ±‚é”™è¯¯: {e}")
        # (æ³¨é‡Š) å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªç‰¹æ®Šçš„é”™è¯¯å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿åç»­å¤„ç†
        return f"ERROR: APIè¯·æ±‚å¤±è´¥ - {e}"

def parse_llm_output_new(llm_text):
    """
    (æ³¨é‡Š)
    è¿™æ˜¯æ–°å¢çš„è§£æå‡½æ•°ï¼Œç”¨äºå¤„ç†æ–°æ ¼å¼çš„LLMè¿”å›ç»“æœã€‚
    å®ƒå–ä»£äº†æ—§çš„ parse_llm_output å‡½æ•°ã€‚
    """
    # (æ³¨é‡Š) æ£€æŸ¥è¿”å›çš„æ˜¯å¦æ˜¯é”™è¯¯ä¿¡æ¯
    if llm_text.startswith("ERROR:"):
        # (æ³¨é‡Š) å¦‚æœæ˜¯é”™è¯¯ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«é”™è¯¯ä¿¡æ¯çš„åˆ—è¡¨
        return [{'chinese_summary': llm_text, 'original_quote': '', 'quote_translation': ''}]

    results = []
    # (æ³¨é‡Š) ä½¿ç”¨ '---' ä½œä¸ºåˆ†éš”ç¬¦ï¼Œå°†LLMè¿”å›çš„å¤šä¸ªè¦ç‚¹åˆ†å‰²æˆåˆ—è¡¨
    sections = llm_text.strip().split('---')
    
    print(f"    è§£æLLMè¾“å‡ºï¼Œæ‰¾åˆ° {len(sections)} ä¸ªè¦ç‚¹...")
    for section in sections:
        if not section.strip():
            continue
        
        # (æ³¨é‡Š) ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å®‰å…¨åœ°æå–æ¯ä¸ªéƒ¨åˆ†çš„å†…å®¹
        summary_match = re.search(r"\[ä¸­æ–‡æç‚¼\]:\s*(.*)", section, re.DOTALL)
        quote_match = re.search(r"\[æ ¸å¿ƒåŸæ–‡\]:\s*(.*)", section, re.DOTALL)
        translation_match = re.search(r"\[åŸæ–‡ç¿»è¯‘\]:\s*(.*)", section, re.DOTALL)
        
        # (æ³¨é‡Š) .strip() ç”¨äºå»é™¤å¯èƒ½å­˜åœ¨çš„å‰åå¤šä½™ç©ºæ ¼æˆ–æ¢è¡Œç¬¦
        chinese_summary = summary_match.group(1).strip() if summary_match else "æœªæå–åˆ°"
        original_quote = quote_match.group(1).strip() if quote_match else "æœªæå–åˆ°"
        quote_translation = translation_match.group(1).strip() if translation_match else "æœªæå–åˆ°"
        
        results.append({
            'chinese_summary': chinese_summary,
            'original_quote': original_quote,
            'quote_translation': quote_translation
        })
        
    return results

# =============================================================================
# --- (æ”¹åŠ¨éƒ¨åˆ† 2): æ›´æ–°ä¸»å¤„ç†æµç¨‹å’ŒExcelç”Ÿæˆ ---
# =============================================================================

def process_pdfs(pdf_files, api_key):
    """
    (æ³¨é‡Š)
    æ›´æ–°ä¸»å¤„ç†å‡½æ•°ï¼Œè°ƒç”¨æ–°çš„åˆ†æå’Œè§£æé€»è¾‘ã€‚
    """
    import_heavy_libraries()
    
    if not api_key or not api_key.strip().startswith("sk-"):
        print("âŒ APIå¯†é’¥æ ¼å¼ä¸æ­£ç¡®")
        # (æ³¨é‡Š) ç›´æ¥è¿”å›ä¸€ä¸ªåŒ…å«é”™è¯¯ä¿¡æ¯çš„å­—å…¸ï¼Œè®©å‰ç«¯çŸ¥é“é—®é¢˜
        return {'error': 'APIå¯†é’¥ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®'}
        
    all_results = []
    
    for idx, pdf_file in enumerate(pdf_files, 1):
        filename = pdf_file.filename
        print(f"ğŸ“„ [{idx}/{len(pdf_files)}] æ­£åœ¨å¤„ç†: {filename}")
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            pdf_file.save(tmp.name)
            pdf_path = tmp.name
            
        try:
            text = smart_extract_text(pdf_path)
            if len(text.strip()) < 200:
                print("    âš ï¸ æå–çš„æ–‡æœ¬å¤ªå°‘ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                continue
            
            # (æ³¨é‡Š) è°ƒç”¨æ–°çš„åˆ†æå‡½æ•°
            llm_output = call_llm_for_analysis(text, api_key)
            # (æ³¨é‡Š) è°ƒç”¨æ–°çš„è§£æå‡½æ•°
            structured_data_list = parse_llm_output_new(llm_output)
            
            # (æ³¨é‡Š) å°†è§£æå‡ºçš„æ¯ä¸ªè¦ç‚¹ä¸æ–‡ä»¶åå…³è”ï¼Œå¹¶æ·»åŠ åˆ°æ€»ç»“æœä¸­
            for item in structured_data_list:
                item['æ–‡ä»¶å'] = filename
                all_results.append(item)
            
            print("    âœ… å¤„ç†æˆåŠŸ\n")
            
        except Exception as e:
            print(f"    âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}\n")
            # (æ³¨é‡Š) å¦‚æœå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°æ„å¤–é”™è¯¯ï¼Œä¹Ÿè®°å½•ä¸‹æ¥
            all_results.append({
                'æ–‡ä»¶å': filename,
                'ä¸­æ–‡æç‚¼': f'å¤„ç†å¤±è´¥: {e}',
                'æ ¸å¿ƒåŸæ–‡': '',
                'åŸæ–‡ç¿»è¯‘': ''
            })
        finally:
            os.unlink(pdf_path)
            
    return all_results

def generate_excel(results):
    """
    (æ³¨é‡Š)
    æ›´æ–°Excelç”Ÿæˆå‡½æ•°ï¼Œä»¥é€‚åº”æ–°çš„æ•°æ®ç»“æ„å’Œåˆ—åã€‚
    """
    if not results:
        return None
    
    df = pd.DataFrame(results)
    
    # (æ³¨é‡Š) å®šä¹‰æ–°çš„åˆ—åå’Œé¡ºåº
    column_order = ['æ–‡ä»¶å', 'ä¸­æ–‡æç‚¼', 'æ ¸å¿ƒåŸæ–‡', 'åŸæ–‡ç¿»è¯‘']
    # (æ³¨é‡Š) ç­›é€‰æ•°æ®ï¼Œç¡®ä¿å³ä½¿æœ‰é”™è¯¯åˆ—ä¹Ÿèƒ½æ­£å¸¸ç”Ÿæˆ
    df = df.reindex(columns=column_order)
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
        df.to_excel(tmp.name, index=False, engine='openpyxl')
        tmp.close()
        beautify_excel_new(tmp.name) # (æ³¨é‡Š) è°ƒç”¨æ–°çš„ç¾åŒ–å‡½æ•°
        return tmp.name

def beautify_excel_new(filepath):
    """
    (æ³¨é‡Š)
    æ–°çš„Excelç¾åŒ–å‡½æ•°ï¼Œæ ¹æ®æ–°çš„åˆ—å®½è¿›è¡Œè°ƒæ•´ã€‚
    """
    wb = load_workbook(filepath)
    ws = wb.active
    
    header_fill = PatternFill(fill_type="solid", fgColor="BDD7EE")
    header_font = Font(bold=True, color="000000")
    header_alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
    thin_border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))
    
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = header_alignment
        cell.border = thin_border

    # (æ³¨é‡Š) è®¾ç½®åˆ—å®½
    ws.column_dimensions['A'].width = 30  # æ–‡ä»¶å
    ws.column_dimensions['B'].width = 55  # ä¸­æ–‡æç‚¼
    ws.column_dimensions['C'].width = 55  # æ ¸å¿ƒåŸæ–‡
    ws.column_dimensions['D'].width = 55  # åŸæ–‡ç¿»è¯‘
    ws.row_dimensions[1].height = 30
    
    for row in ws.iter_rows(min_row=2):
        ws.row_dimensions[row[0].row].height = 120 # (æ³¨é‡Š) å¢åŠ è¡Œé«˜ä»¥å®¹çº³æ›´å¤šå†…å®¹
        for cell in row:
            cell.alignment = Alignment(wrap_text=True, vertical="top", horizontal="left")
            cell.border = thin_border
            
    wb.save(filepath)
    print("    âœ… Excelæ ¼å¼ç¾åŒ–å®Œæˆ")


# =============================================================================
# --- (æœªæ”¹åŠ¨éƒ¨åˆ†): ä¿ç•™äº†å¤§éƒ¨åˆ†çš„PDFæ–‡æœ¬æå–å’Œè¾…åŠ©å‡½æ•° ---
# =============================================================================
def clean_bullet(text):
    text = re.sub(r'^[\s*\-*â€¢Â·#]+', '', text, flags=re.MULTILINE)
    text = text.replace('**', '').replace('*', '').replace('###', '').replace('##', '').replace('#', '')
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()

def smart_extract_text(pdf_path, min_chars=1000):
    print(f"    å°è¯•ç›´æ¥æå–æ–‡æœ¬...")
    try:
        doc = fitz.open(pdf_path)
        text = "\n".join([page.get_text() for page in doc])
        effective_chars = len(''.join(text.split()))
        
        if effective_chars >= min_chars:
            print(f"    âœ… æ–‡æœ¬æå–æˆåŠŸ ({len(text)} å­—ç¬¦)")
            return text
            
        print(f"    âš ï¸ æ–‡æœ¬è¿‡å°‘ ({effective_chars} æœ‰æ•ˆå­—ç¬¦)ï¼Œå¯èƒ½éœ€è¦OCR...")
        # (æ³¨é‡Š) åœ¨WebæœåŠ¡å™¨ç¯å¢ƒä¸‹ï¼ŒOCRä¾èµ–å¤æ‚ä¸”è€—æ—¶ï¼Œæš‚æ—¶ç®€åŒ–é€»è¾‘ï¼Œä¼˜å…ˆä½¿ç”¨æ–‡æœ¬æå–
        # (æ³¨é‡Š) å¦‚æœæ–‡æœ¬æå–æ•ˆæœä¸ä½³ï¼Œå¯ä»¥è€ƒè™‘åç»­ä¸ºOCRåŠŸèƒ½å¢åŠ ä¸“é—¨çš„é…ç½®
        # return ocr_from_pdf(pdf_path) 
        return text # å³ä½¿æ–‡æœ¬å°‘ï¼Œä¹Ÿå…ˆè¿”å›
    except Exception as e:
        print(f"    âŒ æ–‡æœ¬æå–å¤±è´¥: {e}")
        return ""

# (æ³¨é‡Š) ocr_from_pdf å‡½æ•°æš‚æ—¶ä¿ç•™ï¼Œä½†åœ¨ smart_extract_text ä¸­è¢«æ³¨é‡Šæ‰äº†ï¼Œä»¥ç®€åŒ–æœåŠ¡å™¨éƒ¨ç½²
def ocr_from_pdf(pdf_path):
    try:
        images = convert_from_path(pdf_path, dpi=200)
        text_all = ""
        total_pages = len(images)
        for idx, img in enumerate(images, 1):
            print(f"    æ­£åœ¨è¯†åˆ«ç¬¬ {idx}/{total_pages} é¡µ...")
            t = pytesseract.image_to_string(img, lang='chi_sim+eng')
            text_all += f"\n---- ç¬¬{idx}é¡µ ----\n{t}\n"
        print(f"    âœ… OCRè¯†åˆ«å®Œæˆ")
        return text_all
    except Exception as e:
        print(f"    âŒ OCRé”™è¯¯: {e}")
        return ""

def extract_key_sections(pdf_text, max_length=30000):
    if len(pdf_text) <= max_length:
        return pdf_text
    print(f"    æ–‡æœ¬è¿‡é•¿ï¼ˆ{len(pdf_text)}å­—ç¬¦ï¼‰ï¼Œæ™ºèƒ½æå–å…³é”®å†…å®¹...")
    
    key_sections = {
        'æ‘˜è¦': ['abstract', 'summary'],
        'å¼•è¨€': ['introduction', 'background'],
        'æ–¹æ³•': ['method', 'materials and methods'],
        'ç»“æœ': ['result', 'findings'],
        'è®¨è®º': ['discussion', 'analysis'],
        'ç»“è®º': ['conclusion']
    }
    
    extracted_content = []
    # (æ³¨é‡Š) ç®€åŒ–é€»è¾‘ï¼šä¼˜å…ˆæå–æ‘˜è¦ã€ç»“è®ºã€å¼•è¨€å’Œè®¨è®º
    for section_name, keywords in key_sections.items():
        for keyword in keywords:
            try:
                # (æ³¨é‡Š) ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾ä»¥æ¢è¡Œç¬¦å¼€å¤´çš„å…³é”®è¯ï¼Œæ›´å‡†ç¡®
                match = re.search(r'\n\s*' + keyword + r'\s*\n', pdf_text, re.IGNORECASE)
                if match:
                    start_pos = match.start()
                    # (æ³¨é‡Š) å¯»æ‰¾ä¸‹ä¸€ä¸ªç« èŠ‚æ ‡é¢˜ä½œä¸ºç»“æŸä½ç½®
                    next_section_pos = len(pdf_text)
                    for next_kw_list in key_sections.values():
                        for next_kw in next_kw_list:
                            pos = pdf_text.lower().find(f'\n{next_kw}\n', start_pos + 1)
                            if pos != -1:
                                next_section_pos = min(next_section_pos, pos)
                    
                    content = pdf_text[start_pos:next_section_pos]
                    extracted_content.append(content)
                    break # æ‰¾åˆ°ä¸€ä¸ªå…³é”®è¯å°±è·³å‡º
            except Exception:
                continue

    final_text = "\n\n".join(extracted_content)
    if len(final_text) < 5000: # (æ³¨é‡Š) å¦‚æœæå–çš„éƒ¨åˆ†å¤ªå°‘ï¼Œå°±ç”¨æˆªæ–­çš„æ–¹å¼
        final_text = pdf_text[:max_length]

    print(f"    æ™ºèƒ½æå–å®Œæˆï¼Œä¿ç•™äº† {len(final_text)} å­—ç¬¦")
    return final_text


# =============================================================================
# --- Flask åº”ç”¨åˆå§‹åŒ–ä¸è·¯ç”± (è¿™éƒ¨åˆ†åŸºæœ¬ä¸å˜) ---
# =============================================================================
app = Flask(__name__)

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_pdfs():
    pdf_files = request.files.getlist('pdfs')
    api_key = request.form.get('api_key')
    
    if not pdf_files:
        return jsonify({"error": "è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªPDFæ–‡ä»¶"}), 400
        
    print(f"æ”¶åˆ°è¯·æ±‚ï¼šå¤„ç† {len(pdf_files)} ä¸ªæ–‡ä»¶")
    results = process_pdfs(pdf_files, api_key)
    
    # (æ³¨é‡Š) æ£€æŸ¥æ˜¯å¦æ˜¯API Keyé”™è¯¯
    if isinstance(results, dict) and 'error' in results:
        return jsonify(results), 400

    if not results:
        return jsonify({"error": "æœªèƒ½æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹"}), 500

    output_file_path = generate_excel(results)
    if not output_file_path:
        return jsonify({"error": "ç”ŸæˆExcelæ–‡ä»¶å¤±è´¥"}), 500
        
    response = send_file(output_file_path, as_attachment=True, download_name='EggScan_Result_Updated.xlsx')
    
    @response.call_on_close
    def remove_file():
        try:
            os.unlink(output_file_path)
        except Exception as e:
            print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    print("âœ… Excelæ–‡ä»¶å·²å‘é€ï¼Œä»»åŠ¡å®Œæˆã€‚")
    return response

# --- ç¨‹åºä¸»å…¥å£ ---
if __name__ == '__main__':
    # (æ³¨é‡Š) ç§»é™¤ `import_heavy_libraries()` è°ƒç”¨ï¼Œå› ä¸ºå®ƒåº”è¯¥åœ¨è¯·æ±‚æ—¶è¢«è°ƒç”¨ï¼Œè€Œä¸æ˜¯å¯åŠ¨æ—¶
    app.run(host='0.0.0.0', port=5000, debug=True) # (æ³¨é‡Š) å»ºè®®åœ¨å¼€å‘æ—¶å¼€å¯debugæ¨¡å¼

